"""
å®¡é˜…Agent
è¯„ä¼°å›ç­”è´¨é‡ï¼Œæä¾›è¯„åˆ†å’Œæ”¹è¿›å»ºè®®
"""
from typing import List, Dict, Any, Optional
import re
from datetime import datetime

from langchain_community.chat_models import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage
from langchain_community.callbacks.manager import get_openai_callback
from loguru import logger
from pydantic import BaseModel, Field

from ..schemas.agent_state import AgentState, ProcessingStatus
from ..schemas.review_result import ReviewResult
from ..utils.ollama_provider import OllamaProvider


class ReviewAgent:
    """å®¡é˜…Agent"""
    
    def __init__(self, ollama_provider: OllamaProvider):
        """åˆå§‹åŒ–å®¡é˜…Agent"""
        self.llm = ollama_provider.get_llm()
        self.structured_llm = self.llm.with_structured_output(ReviewResult)
        logger.info(f"å®¡é˜…Agentä½¿ç”¨ Ollama æ¨¡å‹: {ollama_provider.model_name}")

    async def review_answer(self, state: AgentState) -> AgentState:
        """å®¡é˜…å›ç­”çš„ä¸»å…¥å£å‡½æ•°"""
        try:
            state.processing_status = ProcessingStatus.PROCESSING
            state.current_step = "review"
            
            # æ‰§è¡Œè´¨é‡è¯„ä¼°
            review_result_dict = await self._evaluate_answer_quality(state)
            # å°†å­—å…¸è½¬æ¢ä¸º ReviewResult å¯¹è±¡
            state.review_result = ReviewResult(**review_result_dict)
            
            # æ ¹æ®è¯„åˆ†å†³å®šä¸‹ä¸€æ­¥
            if state.review_result.approved and state.review_result.score >= state.quality_threshold:
                state.current_step = "completed"
                state.processing_status = ProcessingStatus.COMPLETED
                logger.info(f"å›ç­”é€šè¿‡å®¡æ ¸ï¼Œè¯„åˆ†: {state.review_result.score}/10")
            else:
                if state.revision_count >= state.max_revisions:
                    state.current_step = "max_revisions_reached"
                    state.processing_status = ProcessingStatus.COMPLETED
                    logger.warning(f"è¾¾åˆ°æœ€å¤§ä¿®è®¢æ¬¡æ•°ï¼Œå½“å‰è¯„åˆ†: {state.review_result.score}/10")
                else:
                    state.current_step = "needs_revision"
                    logger.info(f"å›ç­”éœ€è¦ä¿®è®¢ï¼Œè¯„åˆ†: {state.review_result.score}/10")
            
            return state
            
        except Exception as e:
            logger.error(f"å®¡é˜…å¤±è´¥: {str(e)}")
            state.processing_status = ProcessingStatus.FAILED
            state.error_message = f"å®¡é˜…å¤±è´¥: {str(e)}"
            return state
    
    async def _evaluate_answer_quality(self, state: AgentState) -> Dict[str, Any]:
        """ä½¿ç”¨ structured_llm ç›´æ¥è¯„ä¼°å›ç­”è´¨é‡å¹¶è¿”å› ReviewResult å¯¹è±¡ã€‚"""
        
        # æ„å»ºè¯„ä¼°prompt
        evaluation_prompt = self._build_evaluation_prompt(state)
        
        try:
            # structured_llm ä¼šè‡ªåŠ¨è°ƒç”¨ LLM å¹¶å°†è¾“å‡ºè§£æä¸º ReviewResult å¯¹è±¡
            review_result = await self.structured_llm.ainvoke(evaluation_prompt)
            logger.info("ç»“æ„åŒ–å®¡é˜…å®Œæˆã€‚")
            # å°† ReviewResult å¯¹è±¡è½¬æ¢ä¸ºå­—å…¸
            return review_result.dict()
        except Exception as e:
            logger.error(f"ç»“æ„åŒ–å®¡é˜…LLMè°ƒç”¨å¤±è´¥: {e}", exc_info=True)
            # åœ¨å¤±è´¥æ—¶è¿”å›ä¸€ä¸ªé»˜è®¤çš„ã€æ ‡è®°ä¸ºæœªé€šè¿‡çš„ ReviewResult å­—å…¸
            return {
                "score": 1,
                "comment": f"å®¡é˜…æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}",
                "approved": False
            }
    
    def _build_evaluation_prompt(self, state: AgentState) -> str:
        """æ„å»ºè¯„ä¼°prompt"""
        
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å›ç­”è´¨é‡å®¡é˜…å‘˜ã€‚ä½ éœ€è¦ä»å¤šä¸ªç»´åº¦è¯„ä¼°å›ç­”çš„è´¨é‡ï¼Œå¹¶ç»™å‡º1-10çš„è¯„åˆ†ã€‚

è¯„ä¼°ç»´åº¦ï¼š
1. **å‡†ç¡®æ€§** (25%)ï¼šå›ç­”æ˜¯å¦åŸºäºæä¾›çš„ä¿¡æ¯ï¼Œæ˜¯å¦æœ‰äº‹å®é”™è¯¯
2. **å®Œæ•´æ€§** (25%)ï¼šå›ç­”æ˜¯å¦å…¨é¢ï¼Œæ˜¯å¦é—æ¼é‡è¦ä¿¡æ¯
3. **ç›¸å…³æ€§** (20%)ï¼šå›ç­”æ˜¯å¦ç›´æ¥å›åº”äº†ç”¨æˆ·é—®é¢˜
4. **æ¸…æ™°æ€§** (15%)ï¼šå›ç­”æ˜¯å¦ç»“æ„æ¸…æ™°ï¼Œè¡¨è¾¾æ˜ç¡®
5. **æœ‰ç”¨æ€§** (15%)ï¼šå›ç­”æ˜¯å¦å¯¹ç”¨æˆ·æœ‰å®é™…å¸®åŠ©

ä½ éœ€è¦æ ¹æ®ç”¨æˆ·çš„åŸå§‹é—®é¢˜å’Œç”Ÿæˆçš„å›ç­”ï¼Œè¾“å‡ºä¸€ä¸ªJSONå¯¹è±¡ï¼Œè¯¥å¯¹è±¡åŒ…å«ä»¥ä¸‹å­—æ®µï¼š "score" (int), "comment" (str), "approved" (bool)ã€‚
"""

        user_query = state.user_query
        generated_answer = state.generated_answer
        
        evaluation_prompt = f"""{system_prompt}

[åŸå§‹é—®é¢˜]:
{user_query}

[å¾…å®¡é˜…çš„å›ç­”]:
{generated_answer}

è¯·è¾“å‡ºå®¡é˜…ç»“æœçš„JSONå¯¹è±¡ã€‚
"""
        return evaluation_prompt
    
    def generate_feedback_summary(self, state: AgentState) -> str:
        """ç”Ÿæˆåé¦ˆæ‘˜è¦"""
        if not state.review_result:
            return "æš‚æ— å®¡é˜…ç»“æœ"
        
        review = state.review_result
        
        summary = f"""
ğŸ“Š **å›ç­”è´¨é‡è¯„ä¼°æŠ¥å‘Š**

ğŸ“ˆ **è¯„åˆ†ï¼š{review.score}/10** {'âœ… é€šè¿‡' if review.approved else 'âŒ éœ€è¦æ”¹è¿›'}

ğŸ” **è¯„ä¼°æ„è§ï¼š**
{review.comment}"""

        if state.revision_count > 0:
            summary += f"\n\nğŸ”„ **ä¿®è®¢å†å²ï¼š** å½“å‰ä¸ºç¬¬ {state.revision_count} æ¬¡ä¿®è®¢"
        
        return summary
    
    def get_quality_metrics(self, state: AgentState) -> Dict[str, Any]:
        """è·å–è´¨é‡æŒ‡æ ‡"""
        if not state.review_result:
            return {}
        
        review = state.review_result
        
        metrics = {
            "quality_score": review.score,
            "approved": review.approved,
            "revision_count": state.revision_count,
            "needs_improvement": not review.approved and state.revision_count < state.max_revisions,
            "max_revisions_reached": state.revision_count >= state.max_revisions
        }
        
        # è´¨é‡ç­‰çº§
        if review.score >= 9:
            metrics["quality_level"] = "ä¼˜ç§€"
        elif review.score >= 7:
            metrics["quality_level"] = "è‰¯å¥½"
        elif review.score >= 5:
            metrics["quality_level"] = "ä¸€èˆ¬"
        elif review.score >= 3:
            metrics["quality_level"] = "è¾ƒå·®"
        else:
            metrics["quality_level"] = "å¾ˆå·®"
        
        return metrics
    
    async def batch_review(self, answers: List[str], contexts: List[str], queries: List[str]) -> List[ReviewResult]:
        """æ‰¹é‡å®¡é˜…å¤šä¸ªå›ç­”"""
        results = []
        
        for answer, context, query in zip(answers, contexts, queries):
            # åˆ›å»ºä¸´æ—¶çŠ¶æ€è¿›è¡Œè¯„ä¼°
            temp_state = AgentState(
                user_query=query,
                generated_answer=answer,
                relevant_context=context
            )
            
            result = await self._evaluate_answer_quality(temp_state)
            results.append(result)
        
        return results
    
    def create_improvement_prompt(self, state: AgentState) -> str:
        """æ ¹æ®å®¡é˜…ç»“æœåˆ›å»ºç”¨äºæ”¹è¿›çš„prompt"""
        if not state.review_result:
            return ""
            
        feedback = f"ä¹‹å‰çš„å›ç­”å­˜åœ¨ä¸€äº›é—®é¢˜ï¼Œå®¡é˜…åˆ†æ•°ä¸º {state.review_result.score}/10ã€‚\n"
        feedback += f"å®¡é˜…æ„è§: {state.review_result.comment}\n"

        prompt = f"""åŸå§‹é—®é¢˜: {state.user_query}
ç›¸å…³ä¿¡æ¯: {state.retrieved_info}
ä¹‹å‰çš„å›ç­”: {state.generated_answer}

å®¡é˜…åé¦ˆ:
{feedback}

è¯·æ ¹æ®ä»¥ä¸Šåé¦ˆï¼Œç”Ÿæˆä¸€ä¸ªæ›´é«˜è´¨é‡ã€æ›´å®Œå–„çš„æ–°å›ç­”ã€‚
"""
        return prompt 