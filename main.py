"""
LangGraph æ–‡æ¡£é—®ç­”ç³»ç»Ÿä¸»ç¨‹åº
æä¾›å‘½ä»¤è¡Œç•Œé¢æ¥æµ‹è¯•å’Œä½¿ç”¨ç³»ç»Ÿ
"""
import os
import asyncio
import argparse
import signal
from typing import Dict, Any
from pathlib import Path

from dotenv import load_dotenv
from loguru import logger

from src.graphs.document_qa_graph import create_document_qa_graph
from src.schemas.agent_state import get_initial_state
from src.tools.document_tools import create_document_tools
from config import get_config


# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½®æ—¥å¿—
logger.add("logs/document_qa.log", rotation="1 day", retention="7 days")


class DocumentQAApp:
    """æ–‡æ¡£é—®ç­”åº”ç”¨ä¸»ç±»"""
    
    def __init__(self, config: Dict[str, Any] = None, preset: str = "standard"):
        """åˆå§‹åŒ–åº”ç”¨"""
        if config is None:
            # ä½¿ç”¨é…ç½®æ–‡ä»¶çš„é¢„è®¾
            self.config = get_config(preset)
        else:
            self.config = config
        
        # DocumentQAGraph å†…éƒ¨ä¼šè‡ªè¡Œåˆ›å»ºå’Œç®¡ç†æ‰€æœ‰éœ€è¦çš„ç»„ä»¶ï¼ŒåŒ…æ‹¬ DocumentTools
        self.qa_graph = create_document_qa_graph(self.config)
        

    
    async def interactive_mode(self):
        """äº¤äº’æ¨¡å¼"""
        print("ğŸš€ LangGraph æ–‡æ¡£é—®ç­”ç³»ç»Ÿ")
        print("=" * 50)
        print(self.qa_graph.get_graph_visualization())
        print("=" * 50)
        print("ğŸ’¡ ä½¿ç”¨è¯´æ˜ï¼š")
        print("- è¾“å…¥é—®é¢˜å¼€å§‹å¯¹è¯")
        print("- è¾“å…¥ 'tools' æŸ¥çœ‹å¯ç”¨å·¥å…·")
        print("- è¾“å…¥ 'status' æŸ¥çœ‹ç³»ç»ŸçŠ¶æ€")
        print("- è¾“å…¥ 'quit' é€€å‡º")
        print("=" * 50)
        
        session_id = None
        
        while True:
            try:
                try:
                    user_input = input("\nâ“ è¯·è¾“å…¥æ‚¨çš„é—®é¢˜: ").strip()
                except (EOFError, KeyboardInterrupt):
                    print("\nğŸ‘‹ ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­ï¼Œå†è§ï¼")
                    break
                    
                if not user_input:
                    continue
                
                if user_input.lower() == 'quit':
                    print("ğŸ‘‹ å†è§ï¼")
                    break
                
                elif user_input.lower() == 'tools':
                    # å·¥å…·èœå•çš„é€»è¾‘éœ€è¦è°ƒæ•´ï¼Œå› ä¸º document_tools ç°åœ¨ç”± qa_graph ç®¡ç†
                    # ä¸ºç®€åŒ–ï¼Œæš‚æ—¶ç¦ç”¨éƒ¨åˆ†äº¤äº’
                    print("\nğŸ’¡ å·¥å…·è°ƒç”¨åŠŸèƒ½æ­£åœ¨é›†æˆåˆ°ä¸»æµç¨‹ä¸­ã€‚")
                    print("   è¯·ç›´æ¥é€šè¿‡æé—®æ¥ä½¿ç”¨å·¥å…·ï¼Œä¾‹å¦‚ï¼š'æ€»ç»“ä¸€ä¸‹[æ–‡ä»¶å]'")
                    # await self._show_tools_menu()
                    continue
                
                elif user_input.lower() == 'status':
                    if session_id:
                        status = self.qa_graph.get_current_status(session_id)
                        print(f"ğŸ“Š å½“å‰çŠ¶æ€: {status}")
                    else:
                        print("ğŸ“Š æš‚æ— æ´»åŠ¨ä¼šè¯")
                    continue
                
                # å¤„ç†é—®é¢˜
                print("\nğŸ”„ æ­£åœ¨å¤„ç†æ‚¨çš„é—®é¢˜...")
                
                result = await self.qa_graph.run(
                    user_query=user_input,
                    session_id=session_id,
                    config=self.config
                )
                
                session_id = result.session_id
                
                # æ˜¾ç¤ºç»“æœ
                self._display_result(result)
                
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­ï¼Œå†è§ï¼")
                break
            except asyncio.CancelledError:
                print("\n\nâ¹ï¸ ä»»åŠ¡è¢«å–æ¶ˆï¼Œç¨‹åºé€€å‡º")
                break
            except Exception as e:
                import traceback
                error_trace = traceback.format_exc()
                logger.error(f"äº¤äº’æ¨¡å¼å¼‚å¸¸: {str(e)}\n{error_trace}")
                print(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
                
    
    def _display_result(self, result):
        """æ˜¾ç¤ºå¤„ç†ç»“æœ"""
        print("\n" + "=" * 60)
        
        if result.processing_status.value == "failed":
            print(f"âŒ å¤„ç†å¤±è´¥: {result.error_message}")
            return
        
        # æ˜¾ç¤ºå›ç­”
        if result.generated_answer:
            formatted_answer = self.qa_graph.answer_agent.format_final_answer(result)
            print("ğŸ’¬ å›ç­”:")
            print(formatted_answer)
        
        # æ˜¾ç¤ºå®¡é˜…ç»“æœ
        if result.review_result:
            print("\nğŸ“Š **å›ç­”è´¨é‡è¯„ä¼°æŠ¥å‘Š**")
            print(f"ğŸ“ˆ **è¯„åˆ†ï¼š{result.review_result.score}/10** {'âœ… é€šè¿‡' if result.review_result.approved else 'âŒ éœ€è¦æ”¹è¿›'}")
            print(f"\nğŸ” **è¯„ä¼°æ„è§ï¼š**\n{result.review_result.comment}")
            if result.revision_count > 0:
                print(f"\nğŸ”„ **ä¿®è®¢å†å²ï¼š** å½“å‰ä¸ºç¬¬ {result.revision_count} æ¬¡ä¿®è®¢")
        
        print("=" * 60)
    
    async def batch_mode(self, questions_file: str):
        """æ‰¹å¤„ç†æ¨¡å¼"""
        if not os.path.exists(questions_file):
            print(f"âŒ é—®é¢˜æ–‡ä»¶ä¸å­˜åœ¨: {questions_file}")
            return
        
        print(f"ğŸ“ å¼€å§‹æ‰¹å¤„ç†æ¨¡å¼ï¼Œè¯»å–é—®é¢˜æ–‡ä»¶: {questions_file}")
        
        with open(questions_file, 'r', encoding='utf-8') as f:
            questions = [line.strip() for line in f if line.strip()]
        
        results = []
        for i, question in enumerate(questions, 1):
            print(f"\nğŸ”„ å¤„ç†é—®é¢˜ {i}/{len(questions)}: {question}")
            
            result = await self.qa_graph.run(question)
            results.append(result)
            
            # ç®€è¦æ˜¾ç¤ºç»“æœ
            if result.generated_answer:
                print(f"âœ… å›ç­”: {result.generated_answer[:100]}...")
            if result.review_result:
                print(f"ğŸ“Š è¯„åˆ†: {result.review_result.score}/10")
        
        # ä¿å­˜ç»“æœ
        output_file = f"batch_results_{len(questions)}_questions.txt"
        self._save_batch_results(results, output_file)
        print(f"\nğŸ’¾ æ‰¹å¤„ç†ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    
    def _save_batch_results(self, results, output_file: str):
        """ä¿å­˜æ‰¹å¤„ç†ç»“æœ"""
        with open(output_file, 'w', encoding='utf-8') as f:
            for i, result in enumerate(results, 1):
                f.write(f"é—®é¢˜ {i}: {result.user_query}\n")
                f.write(f"å›ç­”: {result.generated_answer}\n")
                if result.review_result:
                    f.write(f"è¯„åˆ†: {result.review_result.score}/10\n")
                    f.write(f"è¯„è¯­: {result.review_result.comment}\n")
                f.write("-" * 80 + "\n\n")
    
    async def demo_mode(self):
        """æ¼”ç¤ºæ¨¡å¼"""
        demo_questions = [
            "è¿™äº›æ–‡æ¡£ä¸»è¦è®²äº†ä»€ä¹ˆå†…å®¹ï¼Ÿ",
            "æ•°æ®åº“ä¸­æœ‰å“ªäº›è¡¨ï¼Ÿ",
            "è¯·æ€»ç»“ä¸€ä¸‹å…³é”®ä¿¡æ¯",
            "æœ‰ä»€ä¹ˆé‡è¦çš„æ•°æ®ç»Ÿè®¡ï¼Ÿ"
        ]
        
        print("ğŸ¬ æ¼”ç¤ºæ¨¡å¼ - è‡ªåŠ¨æµ‹è¯•é¢„è®¾é—®é¢˜")
        print("=" * 50)
        
        for question in demo_questions:
            print(f"\nğŸ¤– è‡ªåŠ¨é—®é¢˜: {question}")
            print("ğŸ”„ å¤„ç†ä¸­...")
            
            result = await self.qa_graph.run(question)
            self._display_result(result)
            
            # ç­‰å¾…ç”¨æˆ·ç¡®è®¤ç»§ç»­
            input("\næŒ‰ Enter ç»§ç»­ä¸‹ä¸€ä¸ªé—®é¢˜...")


async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="LangGraph æ–‡æ¡£é—®ç­”ç³»ç»Ÿ")
    parser.add_argument("--mode", choices=["interactive", "batch", "demo"], 
                       default="interactive", help="è¿è¡Œæ¨¡å¼")
    parser.add_argument("--questions", help="æ‰¹å¤„ç†æ¨¡å¼çš„é—®é¢˜æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--preset", choices=["light", "standard", "performance", "recommended", "code"],
                       default="standard", help="æ¨¡å‹é…ç½®é¢„è®¾")
    parser.add_argument("--provider", choices=["ollama", "openai"],
                       help="LLMæä¾›å•†ï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶è®¾ç½®ï¼‰")
    
    args = parser.parse_args()
    
    # è·å–é…ç½®
    config = get_config(args.preset)
    
    # å¦‚æœæŒ‡å®šäº†æä¾›å•†ï¼Œåˆ™è¦†ç›–é…ç½®
    if args.provider:
        config["provider"] = args.provider
    
    # æ£€æŸ¥æä¾›å•†é…ç½®
    if config["provider"] == "openai" and not config.get("openai_api_key"):
        print("âŒ ä½¿ç”¨OpenAIéœ€è¦è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        return
    elif config["provider"] == "ollama":
        # æ£€æŸ¥Ollamaè¿æ¥
        from src.utils.ollama_provider import test_ollama_connection
        test_result = await test_ollama_connection(config)
        if not test_result["connected"]:
            print(f"âŒ Ollamaè¿æ¥å¤±è´¥: {test_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            print("ğŸ’¡ è¯·ç¡®ä¿OllamaæœåŠ¡æ­£åœ¨è¿è¡Œï¼šollama serve")
            return
        print(f"âœ… Ollamaè¿æ¥æˆåŠŸï¼Œå¯ç”¨æ¨¡å‹: {test_result['models']}")
    
    # åˆ›å»ºå¿…è¦çš„ç›®å½•
    os.makedirs("logs", exist_ok=True)
    
    try:
        # åˆ›å»ºåº”ç”¨å®ä¾‹
        app = DocumentQAApp(config=config)
        
        print(f"ğŸ¤– ä½¿ç”¨ {config['provider'].upper()} æ¨¡å‹: {config['llm_model']}")
        print(f"ğŸ“Š é…ç½®é¢„è®¾: {args.preset}")
        
        # æ ¹æ®æ¨¡å¼è¿è¡Œ
        if args.mode == "interactive":
            await app.interactive_mode()
        elif args.mode == "batch":
            if not args.questions:
                print("âŒ æ‰¹å¤„ç†æ¨¡å¼éœ€è¦æŒ‡å®š --questions å‚æ•°")
                return
            await app.batch_mode(args.questions)
        elif args.mode == "demo":
            await app.demo_mode()
            
    except Exception as e:
        logger.error(f"ä¸»ç¨‹åºå¼‚å¸¸: {str(e)}")
        print(f"âŒ ç¨‹åºè¿è¡Œå¼‚å¸¸: {str(e)}")


if __name__ == "__main__":
    # è¿è¡Œä¸»ç¨‹åº
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­ï¼Œæ­£å¸¸é€€å‡º")
    except Exception as e:
        logger.error(f"ç¨‹åºå¼‚å¸¸é€€å‡º: {str(e)}")
        print(f"âŒ ç¨‹åºå¼‚å¸¸é€€å‡º: {str(e)}") 